{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW1(object):\n",
    "\tdef __init__(self, data_type):\n",
    "\t\tself.inputs = []\n",
    "\t\tself.labels = []\n",
    "\t\tself.learnRate = 1e-10\n",
    "\t\tself.epoch = 10000\n",
    "\t\t#self.weight_1 = np.random.randn(2,2)#np.zeros((2, 2))#([w11, w13], [w12, w14]) \n",
    "\t\t#self.weight_2 = np.random.randn(2,2)#np.zeros((2, 2))#([w21, w23], [w22, w24])\n",
    "\t\t#self.weight_3 = np.random.randn(2,1)#np.zeros((2, 1))#([w31, w32])\n",
    "\t\t#self.neuron_1 = np.random.randn(1,2)#np.zeros((1, 2))#([x11, x12])\n",
    "\t\t#self.neuron_2 = np.random.randn(1,2)#np.zeros((1, 2))#([x21, x22])\n",
    "\t\t#self.neuron_3 = np.random.randn(1,1)#np.zeros((1, 1))#([x3])\n",
    "        \n",
    "        self.w11 =np.random.randn()\n",
    "        self.w12 =np.random.randn()\n",
    "        self.w13 =np.random.randn()\n",
    "        self.w14 =np.random.randn()\n",
    "        \n",
    "        self.b11 =np.random.randn()\n",
    "        self.b12 =np.random.randn()\n",
    "        self.b13 =np.random.randn()\n",
    "        self.b14 =np.random.randn()\n",
    "        \n",
    "        self.w21 =np.random.randn()\n",
    "        self.w22 =np.random.randn()\n",
    "        self.w23 =np.random.randn()\n",
    "        self.w24 =np.random.randn()\n",
    "        \n",
    "        self.b21 =np.random.randn()\n",
    "        self.b22 =np.random.randn()\n",
    "        self.b23 =np.random.randn()\n",
    "        self.b24 =np.random.randn()\n",
    "        \n",
    "        self.w31 =np.random.randn()\n",
    "        self.w32 =np.random.randn()\n",
    "        \n",
    "        self.b31 =np.random.randn()\n",
    "        self.b32 =np.random.randn()        \n",
    "        \n",
    "\t\tif data_type == \"xor\":\n",
    "\t\t\tself.inputs, self.labels = self.generate_XOR_easy()\n",
    "\t\t\tself.pred_y = np.zeros(21)\n",
    "\t\telse:\n",
    "\t\t\tself.inputs, self.labels = self.generate_linear()\n",
    "\t\t\tself.pred_y = np.zeros(100)\n",
    "\n",
    "\tdef generate_linear(self, n=100):\n",
    "\t\tpts = np.random.uniform(0, 1, (n, 2))\n",
    "\t\tinputs = []\n",
    "\t\tlabels = []\n",
    "\t\tfor pt in pts:\n",
    "\t\t\tinputs.append([pt[0], pt[1]])\n",
    "\t\t\tdistance = (pt[0]-pt[1])/1.414\n",
    "\t\t\tif pt[0] > pt[1]:\n",
    "\t\t\t\tlabels.append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels.append(1)\n",
    "\t\treturn np.array(inputs), np.array(labels).reshape(n, 1)\n",
    "\n",
    "\tdef generate_XOR_easy(self):\n",
    "\t\tinputs = []\n",
    "\t\tlabels = []\n",
    "\t\tfor i in range(11):\n",
    "\t\t\tinputs.append([0.1*i, 0.1*i])\n",
    "\t\t\tlabels.append(0)\n",
    "\n",
    "\t\t\tif 0.1*i == 0.5:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tinputs.append([0.1*i, 1-0.1*i])\n",
    "\t\t\tlabels.append(1)\n",
    "\n",
    "\t\treturn np.array(inputs), np.array(labels).reshape(21, 1)\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tfor i in range(self.epoch):\n",
    "\t\t\tloss_sum = 0\n",
    "\t\t\tfor j in range(len(self.inputs)):\n",
    "\t\t\t\t#print(\"iteration :{0}\".format(j))\n",
    "\t\t\t\tinp = self.inputs[j]\n",
    "\t\t\t\tlabel = self.labels[j]\n",
    "\t\t\t\tself.pred_y[j] = self.forward(inp)\n",
    "\t\t\t\tloss = np.mean(np.square(label - self.pred_y))\n",
    "\t\t\t\tself.backward(inp, self.pred_y[j], loss)\n",
    "\t\t\t\tloss_sum += loss\n",
    "\t\t\tif i % 100 == 0:\n",
    "\t\t\t\tloss_sum /= (100*len(self.inputs))\n",
    "\t\t\t\tprint(\"epoch {0} loss {1}\".format(i, loss_sum))\n",
    "\n",
    "\tdef forward(self, inp):\n",
    "\t\tself.neuron_1 = np.array([inp[0]*self.w11+self.b11 + inp[1]*self.w13+self.b13,\n",
    "                                 inp[0]*self.w12+self.b12 + inp[1]*self.w14+self.b14]) #1x2 * 2x2 = 1x2\n",
    "\t\tself.sig_1 = self.sigmoid(self.neuron_1) #1x2\n",
    "\t\t#print(\"sig_1\", self.sig_1)\n",
    "\t\tself.neuron_2 = np.array([inp[0]*self.w21+self.b21 + inp[1]*self.w23+self.b23,\n",
    "                                 inp[0]*self.w22+self.b22 + inp[1]*self.w24+self.b24]) #1x2 * 2x2 = 1x2\n",
    "\t\tself.sig_2 = self.sigmoid(self.neuron_2) #1x2\n",
    "\t\t#print(\"sig_2\", self.sig_2)\n",
    "\t\tself.neuron_3 = np.array(inp[0]*self.w31+self.b31 + inp[1]*self.w32+self.b32) #1x2 * 2x1 = 1x1\n",
    "\t\ty = self.sigmoid(self.neuron_3) #1x1\n",
    "\t\treturn y\n",
    "\n",
    "\tdef backward(self, inp, pred, loss):\n",
    "\t\tp_loss_y = -2*pred*loss\n",
    "\t\tp_y_x3 = self.derivative_sigmoid(pred)\n",
    "\t\tp_x3_w31 = self.sig_2[0]\n",
    "\t\tp_x3_w32 = self.sig_2[1]\n",
    "\n",
    "\t\tp_x3_z21 = self.w31#w31\n",
    "\t\tp_x3_z22 = self.w32#w32\n",
    "\n",
    "\t\tp_z21_x21 = self.derivative_sigmoid(self.sig_2[0])\n",
    "\t\tp_z22_x22 = self.derivative_sigmoid(self.sig_2[1])\n",
    "\n",
    "\t\tp_x21_z11 = self.w21#w21\n",
    "\t\tp_x21_z12 = self.w23#w23\n",
    "\t\tp_x22_z11 = self.w22#w22\n",
    "\t\tp_x22_z12 = self.w24#w24\n",
    "\n",
    "\t\tp_x21_w21 = self.sig_1[0]\n",
    "\t\tp_x21_w23 = self.sig_1[1]\n",
    "\t\tp_x22_w22 = self.sig_1[0]\n",
    "\t\tp_x22_w24 = self.sig_1[1]\n",
    "\n",
    "\t\tp_z11_x11 = self.derivative_sigmoid(self.sig_1[0])\n",
    "\t\tp_z12_x12 = self.derivative_sigmoid(self.sig_1[1])\n",
    "\t\t\n",
    "\t\tp_x11_w11 = inp[0]#x01\n",
    "\t\tp_x11_w13 = inp[1]#x02\n",
    "\t\tp_x12_w12 = inp[0]#x01\n",
    "\t\tp_x12_w14 = inp[1]#x02\n",
    "\n",
    "\t\tp_loss_x3 = p_loss_y * p_y_x3\n",
    "\t\tp_x3_x21 = p_x3_z21 * p_z21_x21\n",
    "\t\tp_x3_x22 = p_x3_z22 * p_z22_x22\n",
    "\n",
    "\t\tself.weight_3[0] += self.learnRate * p_loss_x3 * p_x3_w31\n",
    "\t\tself.weight_3[1] += self.learnRate * p_loss_x3 * p_x3_w32\n",
    "\n",
    "\t\tself.weight_2[0][0] += self.learnRate * p_loss_x3 * p_x3_x21 * p_x21_w21\n",
    "\t\tself.weight_2[1][0] += self.learnRate * p_loss_x3 * p_x3_x21 * p_x21_w23\n",
    "\t\tself.weight_2[0][1] += self.learnRate * p_loss_x3 * p_x3_x22 * p_x22_w22\n",
    "\t\tself.weight_2[1][1] += self.learnRate * p_loss_x3 * p_x3_x22 * p_x22_w24\n",
    "\n",
    "\t\tp_x3_x11 = (p_x3_x21*p_x21_z11 + p_x3_x22*p_x22_z11)*p_z11_x11\n",
    "\t\tp_x3_x12 = (p_x3_x21*p_x21_z12 + p_x3_x22*p_x22_z12)*p_z12_x12\n",
    "\n",
    "\t\tself.weight_1[0][0] += self.learnRate * p_loss_x3 * p_x3_x11 * p_x11_w11\n",
    "\t\tself.weight_1[1][0] += self.learnRate * p_loss_x3 * p_x3_x11 * p_x11_w13\n",
    "\t\tself.weight_1[0][1] += self.learnRate * p_loss_x3 * p_x3_x12 * p_x12_w12\n",
    "\t\tself.weight_1[1][1] += self.learnRate * p_loss_x3 * p_x3_x12 * p_x12_w14\n",
    "\n",
    "\n",
    "\tdef sigmoid(self, x):\n",
    "\t\treturn 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "\tdef derivative_sigmoid(self, x):\n",
    "\t\treturn np.multiply(x, 1.0 - x)\n",
    "\n",
    "\tdef test(self):\n",
    "\t\tfor pred in self.pred_y:\n",
    "\t\t\tprint(pred)\n",
    "\n",
    "\tdef show_result(self):\n",
    "\t\tplt.subplot(1,2,1)\n",
    "\t\tplt.title('Ground truth', fontsize=18)\n",
    "\t\tfor i in range(len(self.inputs)):\n",
    "\t\t\tif self.labels[i] == 0:\n",
    "\t\t\t\tplt.plot(self.inputs[i][0], self.inputs[i][1], 'ro')\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.plot(self.inputs[i][0], self.inputs[i][1], 'bo')\n",
    "\t\tplt.subplot(1,2,2)\n",
    "\t\tplt.title('Predict result', fontsize=18)\n",
    "\t\tfor i in range(len(self.inputs)):\n",
    "\t\t\tif self.pred_y[i] == 0:\n",
    "\t\t\t\tplt.plot(self.inputs[i][0], self.inputs[i][1], 'ro')\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.plot(self.inputs[i][0], self.inputs[i][1], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.003465059128662465\n",
      "epoch 100 loss 0.002496342566887012\n",
      "epoch 200 loss 0.0024963425665059666\n",
      "epoch 300 loss 0.002496342566124921\n",
      "epoch 400 loss 0.002496342565743877\n",
      "epoch 500 loss 0.002496342565362832\n",
      "epoch 600 loss 0.0024963425649817865\n",
      "epoch 700 loss 0.0024963425646007415\n",
      "epoch 800 loss 0.0024963425642196974\n",
      "epoch 900 loss 0.002496342563838652\n",
      "epoch 1000 loss 0.002496342563457607\n",
      "epoch 1100 loss 0.0024963425630765623\n",
      "epoch 1200 loss 0.0024963425626955173\n",
      "epoch 1300 loss 0.002496342562314473\n",
      "epoch 1400 loss 0.0024963425619334285\n",
      "epoch 1500 loss 0.002496342561552384\n",
      "epoch 1600 loss 0.0024963425611713385\n",
      "epoch 1700 loss 0.0024963425607902943\n",
      "epoch 1800 loss 0.00249634256040925\n",
      "epoch 1900 loss 0.0024963425600282056\n",
      "epoch 2000 loss 0.0024963425596471614\n",
      "epoch 2100 loss 0.002496342559266117\n",
      "epoch 2200 loss 0.0024963425588850727\n",
      "epoch 2300 loss 0.0024963425585040285\n",
      "epoch 2400 loss 0.0024963425581229844\n",
      "epoch 2500 loss 0.00249634255774194\n",
      "epoch 2600 loss 0.0024963425573608956\n",
      "epoch 2700 loss 0.0024963425569798515\n",
      "epoch 2800 loss 0.0024963425565988073\n",
      "epoch 2900 loss 0.002496342556217764\n",
      "epoch 3000 loss 0.00249634255583672\n",
      "epoch 3100 loss 0.0024963425554556753\n",
      "epoch 3200 loss 0.0024963425550746316\n",
      "epoch 3300 loss 0.0024963425546935883\n",
      "epoch 3400 loss 0.002496342554312544\n",
      "epoch 3500 loss 0.0024963425539315\n",
      "epoch 3600 loss 0.0024963425535504567\n",
      "epoch 3700 loss 0.0024963425531694134\n",
      "epoch 3800 loss 0.0024963425527883693\n",
      "epoch 3900 loss 0.002496342552407326\n",
      "epoch 4000 loss 0.002496342552026282\n",
      "epoch 4100 loss 0.0024963425516452385\n",
      "epoch 4200 loss 0.0024963425512641952\n",
      "epoch 4300 loss 0.002496342550883152\n",
      "epoch 4400 loss 0.0024963425505021082\n",
      "epoch 4500 loss 0.0024963425501210654\n",
      "epoch 4600 loss 0.0024963425497400217\n",
      "epoch 4700 loss 0.002496342549358979\n",
      "epoch 4800 loss 0.002496342548977935\n",
      "epoch 4900 loss 0.0024963425485968922\n",
      "epoch 5000 loss 0.002496342548215849\n",
      "epoch 5100 loss 0.002496342547834806\n",
      "epoch 5200 loss 0.0024963425474537632\n",
      "epoch 5300 loss 0.0024963425470727195\n",
      "epoch 5400 loss 0.0024963425466916762\n",
      "epoch 5500 loss 0.0024963425463106342\n",
      "epoch 5600 loss 0.002496342545929592\n",
      "epoch 5700 loss 0.002496342545548548\n",
      "epoch 5800 loss 0.0024963425451675057\n",
      "epoch 5900 loss 0.0024963425447864624\n",
      "epoch 6000 loss 0.0024963425444054204\n",
      "epoch 6100 loss 0.0024963425440243775\n",
      "epoch 6200 loss 0.002496342543643335\n",
      "epoch 6300 loss 0.0024963425432622923\n",
      "epoch 6400 loss 0.0024963425428812503\n",
      "epoch 6500 loss 0.002496342542500207\n",
      "epoch 6600 loss 0.0024963425421191654\n",
      "epoch 6700 loss 0.002496342541738122\n",
      "epoch 6800 loss 0.0024963425413570797\n",
      "epoch 6900 loss 0.0024963425409760378\n",
      "epoch 7000 loss 0.002496342540594995\n",
      "epoch 7100 loss 0.0024963425402139534\n",
      "epoch 7200 loss 0.0024963425398329114\n",
      "epoch 7300 loss 0.002496342539451869\n",
      "epoch 7400 loss 0.0024963425390708274\n",
      "epoch 7500 loss 0.002496342538689785\n",
      "epoch 7600 loss 0.0024963425383087426\n",
      "epoch 7700 loss 0.002496342537927701\n",
      "epoch 7800 loss 0.0024963425375466594\n",
      "epoch 7900 loss 0.002496342537165617\n",
      "epoch 8000 loss 0.0024963425367845755\n",
      "epoch 8100 loss 0.0024963425364035335\n",
      "epoch 8200 loss 0.002496342536022491\n",
      "epoch 8300 loss 0.00249634253564145\n",
      "epoch 8400 loss 0.0024963425352604075\n",
      "epoch 8500 loss 0.002496342534879366\n",
      "epoch 8600 loss 0.002496342534498325\n",
      "epoch 8700 loss 0.0024963425341172833\n",
      "epoch 8800 loss 0.0024963425337362413\n",
      "epoch 8900 loss 0.0024963425333552\n",
      "epoch 9000 loss 0.002496342532974159\n",
      "epoch 9100 loss 0.0024963425325931175\n",
      "epoch 9200 loss 0.0024963425322120755\n",
      "epoch 9300 loss 0.002496342531831035\n",
      "epoch 9400 loss 0.0024963425314499937\n",
      "epoch 9500 loss 0.0024963425310689526\n",
      "epoch 9600 loss 0.002496342530687911\n",
      "epoch 9700 loss 0.00249634253030687\n",
      "epoch 9800 loss 0.0024963425299258284\n",
      "epoch 9900 loss 0.0024963425295447877\n"
     ]
    }
   ],
   "source": [
    "foo = HW1('xor')\n",
    "foo.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500255170625\n",
      "0.494991384805\n",
      "0.497976557147\n",
      "0.493802455116\n",
      "0.495704367625\n",
      "0.492615823799\n",
      "0.493455982775\n",
      "0.491433611853\n",
      "0.491246871011\n",
      "0.490257677674\n",
      "0.489089577496\n",
      "0.486993295325\n",
      "0.487930542251\n",
      "0.484963986315\n",
      "0.486781475903\n",
      "0.483004885251\n",
      "0.485642979033\n",
      "0.481117179853\n",
      "0.484515399153\n",
      "0.479300691204\n",
      "0.483398905942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foo.test()\n",
    "foo.show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ],\n",
       "       [ 0. ,  1. ],\n",
       "       [ 0.1,  0.1],\n",
       "       [ 0.1,  0.9],\n",
       "       [ 0.2,  0.2],\n",
       "       [ 0.2,  0.8],\n",
       "       [ 0.3,  0.3],\n",
       "       [ 0.3,  0.7],\n",
       "       [ 0.4,  0.4],\n",
       "       [ 0.4,  0.6],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.6,  0.6],\n",
       "       [ 0.6,  0.4],\n",
       "       [ 0.7,  0.7],\n",
       "       [ 0.7,  0.3],\n",
       "       [ 0.8,  0.8],\n",
       "       [ 0.8,  0.2],\n",
       "       [ 0.9,  0.9],\n",
       "       [ 0.9,  0.1],\n",
       "       [ 1. ,  1. ],\n",
       "       [ 1. ,  0. ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
